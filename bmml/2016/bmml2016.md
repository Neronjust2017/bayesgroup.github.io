---
layout: page
permalink: /bmml/
---

## Байесовские методы машинного обучения (курс лекций) / 2016

<img src="/images/bmmo.png" width="40%" align="right" style="Margin-left: 10px; Margin-right: 10px; *margin-left: -10px; *margin-right: -10px"/>
Курс посвящен т.н. байесовским методам решения различных задач машинного обучения (классификации, восстановления регрессии, уменьшения размерности, разделения смесей, тематического моделирования и др.), которые в настоящее время активно развиваются в мире. Большинство современных научных публикаций по машинному обучению используют вероятностное моделирование, опирающееся на байесовский подход к теории вероятностей. Последний позволяет эффективно учитывать различные предпочтения пользователя при построении решающих правил прогноза. Кроме того, он позволяет решать задачи выбора структурных параметров модели. В частности, здесь удается решать без комбинаторного перебора задачи селекции признаков, выбора числа кластеров в данных, размерности редуцированного пространства при уменьшении размерности, значений коэффициентов регуляризации и пр. В байесовском подходе вероятность интерпретируется как мера незнания, а не как объективная случайность. Простые правила оперирования с вероятностью, такие как формула полной вероятности и формула Байеса, позволяют проводить рассуждения в условиях неопределенности. В этом смысле байесовский подход к теории вероятностей можно рассматривать как обобщение классической булевой логики. Основной задачей курса является привитие студентам навыков самостоятельного построения сложных вероятностных моделей обработки данных, используя стандартные модели в качестве своеобразных "кирпичиков". Особое внимание уделяется приближенным байесовским методам, позволяющим обсчитывать сложные вероятностные модели.

<br />
**Лектор**: Д.П. Ветров <br />
**Семинаристы**: Е. Лобачева, Д. Подоприхин

**Таблица с результатами находится [здесь](https://docs.google.com/spreadsheets/d/1EWr2XJOpnr5CAHnzP_WVWBCnbdPu25K0TnJIp5wK8oU/edit?usp=sharing).**

Вопросы и комментарии по курсу, а также сдаваемые задания нужно отправлять на почту **bayesml@gmail.com**. В название письма обязательно добавлять тег **[БММО16]**.

Формат темы письма:

* **[БММО16]Вопрос** — для вопросов;
* **[БММО16]Практика №, Фамилия Имя, Вариант №** — для практический заданий (если вариант только один, то его указывать не нужно);
* **[БММО16]Теория №, Фамилия Имя** — для домашних заданий.

Просьба не смешивать темы, то есть не нужно присылать в одном письме практическое задание и домашнее.

## Расписание занятий

В 2016 году курс читается на факультете ВМК МГУ по пятницам в ауд. 508, начало в 14-35 (лекция) и 16-20 (семинар).

| Дата | № | Занятие | Материалы |
|------|---|---------|-----------|
|2 сентября|1|Лекция «Байесовский подход к теории вероятностей. Примеры байесовских рассуждений.»|[Конспект](/bmml/2016/Lectures/lecture01_summary.pdf), [Презентация](/bmml/2016/Lectures/lecture01_presentation.pdf)|
|| |Семинар «Байесовские рассуждения. Выдача практического задания №1»|[Задачи](/bmml/2016/Seminars/BMML_sem1_2016.pdf)|
|9 сентября|2|Лекция «Сопряжённые распределения, аналитический байесовский вывод, экспоненциальный класс распределений»||
|||Семинар «Сопряжённые распределения»|[Задачи](/bmml/2016/Seminars/BMML_sem2_2016.pdf)|
|16 сентября|3|Лекция «Байесовский выбор модели»|[Презентация](/bmml/2016/Lectures/lecture03_presentation.pdf)|
|| |Семинар «Подсчёт обоснованности моделей»||
|23 сентября|4|Лекция «Метод релевантных векторов для задачи регрессии»|[Презентация](/bmml/2016/Lectures/lecture04_presentation.pdf)|
|| |Семинар «Матричные вычисления»||
|30 сентября|5|	Лекция «Метод релевантных векторов для задачи классификации»|[Презентация](/bmml/2016/Lectures/lecture05_summary.pdf)|
|| |Семинар «Метод релевантных векторов»||
|7 октября|6|	Лекция «EM-алгоритм. Байесовский метод главных компонент»|[Презентация](/bmml/2016/Lectures/lecture06_summary.pdf)|
|| |Семинар «ЕМ-алгоритм»||

## Теоретические задания

Задание 1. [Сопряжённые распределения и экспоненциальный класс распределений](/bmml/2016/Hometasks/BMML_hw1_2016.pdf)<br />
Срок сдачи: 16 сентября (пятница), 23:59.

## Практические задания

Задание 1. [Байесовские рассуждения](/bmml/2016/Hometasks/BMML_Assignment1_2016.pdf)<br />
Проверьте свой код перед сдачей с помощью данного [тестера](/bmml/2016/Hometasks/BMML1_tester_for_students.ipynb)!<br />
Срок сдачи: 17 сентября (суббота), 23:59.

## Система выставления оценок по курсу

1. В рамках курса предполагается выполнение трёх практических заданий и трёх домашних заданий.
2. Задания выполняются самостоятельно. Если задание выполнялось сообща, или использовались какие-либо сторонние коды и материалы, то об этом должно быть написано в отчете. В противном случае „похожие“ решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) будут сурово наказаны.
3. При наличии несданных практических заданий максимальная возможная оценка за курс — это «удовлетворительно».
4. Практические задания оцениваются из 5 баллов. За сдачу заданий позже срока начисляется штраф в размере 0.1 балла за каждый день просрочки, но суммарно не более 5-и баллов.
5. Домашние задания оцениваются из 2 баллов. За сдачу заданий позже срока начисляется штраф в размере 0.1 балла за каждый день просрочки. Задания не принимаются спустя неделю после срока.
6. Необходимым условием получения положительной оценки за курс является сдача не менее двух практических заданий и сдача устного экзамена не менее чем на оценку «удовлетворительно».
7. Итоговая оценка вычисляется по формуле **Mark = (Oral*4+HomeWork)/8**, где Oral — оценка за устный экзамен (0, 3, 4, 5), HomeWork — баллы, набранные за практические и домашние задания (см. таблицу выше), Mark — итоговая оценка по 5-балльной шкале. Нецелые значения округляются в сторону ближайшего целого, **превосходящего** дробное значение.
8. На экзамене студент может отказаться от оценки и пойти на пересдачу, на которой может заново получить Oral.
9. За каждое несданное практическое задание выставляется минус 10 баллов в баллы по заданиям (допускаются отрицательные значения).
10. За каждую несданное домашнее задание выставляется 0 баллов в баллы по заданиям.
11. Если на экзамене итоговая оценка оказывается ниже трех, то студент отправляется на пересдачу. При этом оценка Oral, полученная на пересдаче, добавляется к положительной (три и выше) оценке Oral, полученной на основном экзамене и т.д. до тех пор, пока студент не наберет на итоговую оценку «удовлетворительно» (для итоговых оценок выше «удовлетворительно» оценки Oral не суммируются).
12. Студент может досдать недостающие практические задания в любое время. При этом проверка задания гарантируется только в том случае, если задание сдано не позднее, чем за неделю до основного экзамена или пересдачи.
13. В случае успешной сдачи всех практических заданий студент получает возможность претендовать на итоговую оценку «хорошо» и «отлично». При этом экзамен на оценку Oral может сдаваться до сдачи всех заданий (оценки Oral в этом случае **не суммируются**).
14. Экзамен на оценку Oral сдается либо в срок основного экзамена, либо в срок официальных пересдач.

## Литература

* *Barber D.* [Bayesian Reasoning and Machine Learning.](http://www0.cs.ucl.ac.uk/staff/d.barber/brml/) Cambridge University Press, 2012. 
* [Набор полезных фактов для матричных вычислений](http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3274/pdf/imm3274.pdf)
* Простые и удобные [заметки по матричным вычислениям и свойствам гауссовских распределений](http://cs.nyu.edu/~roweis/notes.html)
* [Памятка по теории вероятностей](http://matthias.vallentin.net/probability-and-statistics-cookbook/)
* *Ветров Д.П., Кропотов Д.А.* Байесовские методы машинного обучения, учебное пособие по спецкурсу, 2007 ([Часть 1, PDF 1.22МБ](/bmml/2016/BayesML-2007-textbook-1.pdf); [Часть 2, PDF 1.58МБ](/bmml/2016/BayesML-2007-textbook-2.pdf))
* *Bishop C.M.* [Pattern Recognition and Machine Learning.](http://research.microsoft.com/en-us/um/people/cmbishop/prml/) Springer, 2006.
* *Mackay D.J.C.* [Information Theory, Inference, and Learning Algorithms.](http://www.inference.phy.cam.ac.uk/mackay/itila/book.html) Cambridge University Press, 2003.
* *Tipping M.* [Sparse Bayesian Learning.](http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf) Journal of Machine Learning Research, 1, 2001, pp. 211-244.
* *Шумский С.А.* [Байесова регуляризация обучения.](http://www.niisi.ru/iont/ni/Library/School-2002/Shumsky-2002.pdf) В сб. Лекции по нейроинформатике, часть 2, 2002.

## Страницы курса прошлых лет
[2010 год](http://www.machinelearning.ru/wiki/index.php?title=Байесовские_методы_машинного_обучения_%28курс_лекций%2C_Д.П._Ветров%2C_Д.А._Кропотов%2C_2010%29)<br />
[2011 год](http://www.machinelearning.ru/wiki/index.php?title=Байесовские_методы_машинного_обучения_%28курс_лекций%2C_Д.П._Ветров%2C_Д.А._Кропотов%29/2011)<br />
[весна 2013 года](http://www.machinelearning.ru/wiki/index.php?title=Байесовские_методы_машинного_обучения_%28курс_лекций%2C_Д.П._Ветров%2C_Д.А._Кропотов%29/весна_2013)<br />
[осень 2013 года](http://www.machinelearning.ru/wiki/index.php?title=Байесовские_методы_машинного_обучения_%28курс_лекций%2C_Д.П._Ветров%2C_Д.А._Кропотов%29/осень_2013)<br />
[2014 год](http://www.machinelearning.ru/wiki/index.php?title=Байесовские_методы_машинного_обучения_%28курс_лекций%2C_Д.П._Ветров%2C_Д.А._Кропотов%29/2014)<br />
[2015 год](http://www.machinelearning.ru/wiki/index.php?title=Байесовские_методы_машинного_обучения_%28курс_лекций%2C_Д.П._Ветров%2C_Д.А._Кропотов%29/2015)<br />

## См. также
[Курс "Графические модели"](http://www.machinelearning.ru/wiki/index.php?title=ГМ)<br />
[Спецсеминар «Байесовские методы машинного обучения»](http://www.machinelearning.ru/wiki/index.php?title=Спецсеминар_"Байесовские_методы_машинного_обучения")<br />
[Математические методы прогнозирования (кафедра ВМК МГУ)](http://www.machinelearning.ru/wiki/index.php?title=Математические_методы_прогнозирования_%28кафедра_ВМиК_МГУ%29)<br />
